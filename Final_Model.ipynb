{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0122fe4f",
   "metadata": {},
   "source": [
    "1. 인삼 모델을 만든다.\n",
    "\n",
    "2. 모델의 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c6981",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21eff81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c512d",
   "metadata": {},
   "source": [
    "Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3373276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test와 df_train 파일이 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "dfdf = pd.read_csv('train_under.csv')\n",
    "\n",
    "df_test_상 = dfdf[dfdf['label'] == '상'].sample(n=1000, random_state=42)\n",
    "df_test_중 = dfdf[dfdf['label'] == '중'].sample(n=1000, random_state=42)\n",
    "df_test_하 = dfdf[dfdf['label'] == '하'].sample(n=1000, random_state=42)\n",
    "df_test_최하 = dfdf[dfdf['label'] == '최하'].sample(n=1000, random_state=42)\n",
    "\n",
    "df_test = pd.concat([df_test_상, df_test_중, df_test_하, df_test_최하])\n",
    "\n",
    "df_train = dfdf.drop(df_test.index)\n",
    "\n",
    "df_test.to_csv('df_test.csv', index=False)\n",
    "df_train.to_csv('df_train.csv', index=False)\n",
    "\n",
    "print(\"df_test와 df_train 파일이 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39122bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "상     4263\n",
       "중     4263\n",
       "최하    4263\n",
       "하     4263\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdf['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f3700",
   "metadata": {},
   "source": [
    "File tranforming.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f6dc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 404/404 [03:48<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'D:/249.진안홍삼 품질 데이터/01-1.정식개방데이터/Validation/01.원천데이터/'\n",
    "label_dir = 'D:/249.진안홍삼 품질 데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/'\n",
    "\n",
    "train_folder = os.listdir(train_dir)\n",
    "label_folder = os.listdir(label_dir)\n",
    "\n",
    "\n",
    "dest_dir = 'C:/workspace/Insam/test'\n",
    "\n",
    "test_df = pd.DataFrame(columns=['file_path', 'label'])\n",
    "\n",
    "for folder in tqdm(train_folder):\n",
    "    folder_path = os.path.join(train_dir, folder)\n",
    "    label = folder.split('_')[1]\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                if img.mode == 'RGB':\n",
    "                    new_file_name = f\"{label}_{file_name}\"\n",
    "                    dest_file_path = os.path.join(dest_dir, new_file_name)\n",
    "                    shutil.copy(file_path, dest_file_path)\n",
    "                    test_df = test_df.append({'file_path': dest_file_path, 'label': label}, ignore_index=True)\n",
    "                    \n",
    "        except IOError:\n",
    "            print(f\"Error opening file {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8075a74",
   "metadata": {},
   "source": [
    "Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9569b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {'상': 0, '중': 1, '하': 2, '최하': 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df['file_path'].iloc[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        target_label = self.df['label'].iloc[idx]\n",
    "        target = self.label_mapping[target_label]\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "        return image, target\n",
    "    \n",
    "mytransform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "myvaltransform =transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, class_n, rate=0.2):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        self.output_layer = nn.Linear(in_features=1000, \n",
    "                                      out_features=class_n, bias=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.output_layer(self.dropout(self.model(inputs)))\n",
    "        return output\n",
    "    \n",
    "def train_step(model, batch_item, epoch, training, class_weight=None):\n",
    "    img, label = batch_item\n",
    "#     img = torch.tensor(img, dtype=torch.float32).detach()\n",
    "#     label = torch.tensor(self.label, dtype=torch.long)\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "    if training:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "    \n",
    "    # 정확도 계산\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct = (pred == label).float() \n",
    "    accuracy = correct.mean() \n",
    "\n",
    "    return loss, accuracy\n",
    "    \n",
    "def predict(models,dataset):\n",
    "    for fold,model in enumerate(models):\n",
    "        model.eval()\n",
    "    tqdm_dataset = tqdm(enumerate(dataset))\n",
    "    training = False\n",
    "    results = []\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        img = batch_item['img'].to(device)\n",
    "        for fold,model in enumerate(models):\n",
    "            with torch.no_grad():\n",
    "                if fold ==0:\n",
    "                    output = model(img)\n",
    "                else:\n",
    "                    output = output+model(img)\n",
    "        output = 0.2*output\n",
    "        output = torch.tensor(torch.argmax(output, axis=-1), dtype=torch.int32).cpu().numpy()\n",
    "        results.extend(output)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab2eb7",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0196cdd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "## ready to dataset to train## \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:39<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 0.8937, Accuracy: 0.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:34<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Loss: 0.6829, Accuracy: 0.7145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Loss: 0.6311, Accuracy: 0.7363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:37<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - Loss: 0.6015, Accuracy: 0.7519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:37<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Loss: 0.5724, Accuracy: 0.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - Loss: 0.5535, Accuracy: 0.7794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Loss: 0.5408, Accuracy: 0.7811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:34<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - Loss: 0.5152, Accuracy: 0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:36<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - Loss: 0.4997, Accuracy: 0.7954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Loss: 0.4846, Accuracy: 0.8053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - Loss: 0.4699, Accuracy: 0.8152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:36<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Loss: 0.4505, Accuracy: 0.8210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - Loss: 0.4440, Accuracy: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 - Loss: 0.4203, Accuracy: 0.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 - Loss: 0.4049, Accuracy: 0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:36<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - Loss: 0.3913, Accuracy: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 - Loss: 0.3660, Accuracy: 0.8518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 - Loss: 0.3525, Accuracy: 0.8606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:34<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - Loss: 0.3422, Accuracy: 0.8666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:36<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 - Loss: 0.3234, Accuracy: 0.8708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:41<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - Loss: 0.3070, Accuracy: 0.8819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:42<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - Loss: 0.2905, Accuracy: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:33<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 - Loss: 0.2719, Accuracy: 0.8910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:36<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 - Loss: 0.2636, Accuracy: 0.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:36<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 - Loss: 0.2451, Accuracy: 0.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:37<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - Loss: 0.2319, Accuracy: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:38<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 - Loss: 0.2192, Accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:39<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 - Loss: 0.2131, Accuracy: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:37<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 - Loss: 0.1996, Accuracy: 0.9236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:36<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 - Loss: 0.1837, Accuracy: 0.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 816/816 [03:02<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: New best validation loss: 0.1624. Saving model...\n",
      "Epoch 30/30 - Val Loss: 0.1624\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\")\n",
    "    batch_size = 16\n",
    "    random_seed=42\n",
    "    learning_rate = 1e-4\n",
    "    epochs = 30\n",
    "    \n",
    "    model = CNN_Model(4).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    train_dataset = CustomDataset(csv_file='./df_train.csv', transform=mytransform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = CustomDataset(csv_file='./df_test.csv', transform=mytransform)\n",
    "    test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(\"## ready to dataset to train## \")\n",
    "    \n",
    "    training = True\n",
    "    loss_plot, val_loss_plot = [], []\n",
    "    acc_plot, val_acc_plot = [], []\n",
    "\n",
    "    # Training\n",
    "    best_val_loss = np.inf \n",
    "    for epoch in range(epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        total_batches = 0\n",
    "\n",
    "        for batch_item in tqdm(train_loader):\n",
    "            batch_loss, batch_acc = train_step(model, batch_item, epoch, training)\n",
    "            total_loss += batch_loss.item() \n",
    "            total_acc += batch_acc.item() \n",
    "            total_batches += 1 \n",
    "\n",
    "        epoch_loss = total_loss / total_batches\n",
    "        epoch_acc = total_acc / total_batches\n",
    "\n",
    "        loss_plot.append(epoch_loss)\n",
    "        acc_plot.append(epoch_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "        \n",
    "    model.eval() \n",
    "    total_val_loss = 0\n",
    "    total_val_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_item in tqdm(test_loader):\n",
    "            batch_loss, _ = train_step(model, batch_item, epoch, False)  # training=False\n",
    "            total_val_loss += batch_loss.item()\n",
    "            total_val_batches += 1\n",
    "\n",
    "    val_loss = total_val_loss / total_val_batches\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"Epoch {epoch+1}: New best validation loss: {val_loss:.4f}. Saving model...\")\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8c63c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4058</td>\n",
       "      <td>C:/workspace/Insam/train\\상_20220831_Xray_00035...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2046</td>\n",
       "      <td>C:/workspace/Insam/train\\상_20220804_Xray_00231...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3177</td>\n",
       "      <td>C:/workspace/Insam/train\\상_20220816_Xray_00091...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4534</td>\n",
       "      <td>C:/workspace/Insam/train\\상_20220915_Xray_00138...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2935</td>\n",
       "      <td>C:/workspace/Insam/train\\상_20220811_Xray_00301...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17047</th>\n",
       "      <td>135209</td>\n",
       "      <td>C:/workspace/Insam/train\\하_20220901_Xray_00282...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17048</th>\n",
       "      <td>128532</td>\n",
       "      <td>C:/workspace/Insam/train\\하_20220817_Xray_00102...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17049</th>\n",
       "      <td>136378</td>\n",
       "      <td>C:/workspace/Insam/train\\하_20220906_Xray_00052...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17050</th>\n",
       "      <td>129960</td>\n",
       "      <td>C:/workspace/Insam/train\\하_20220819_Xray_00116...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17051</th>\n",
       "      <td>134016</td>\n",
       "      <td>C:/workspace/Insam/train\\하_20220830_Xray_00187...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17052 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          file_path label\n",
       "0            4058  C:/workspace/Insam/train\\상_20220831_Xray_00035...     상\n",
       "1            2046  C:/workspace/Insam/train\\상_20220804_Xray_00231...     상\n",
       "2            3177  C:/workspace/Insam/train\\상_20220816_Xray_00091...     상\n",
       "3            4534  C:/workspace/Insam/train\\상_20220915_Xray_00138...     상\n",
       "4            2935  C:/workspace/Insam/train\\상_20220811_Xray_00301...     상\n",
       "...           ...                                                ...   ...\n",
       "17047      135209  C:/workspace/Insam/train\\하_20220901_Xray_00282...     하\n",
       "17048      128532  C:/workspace/Insam/train\\하_20220817_Xray_00102...     하\n",
       "17049      136378  C:/workspace/Insam/train\\하_20220906_Xray_00052...     하\n",
       "17050      129960  C:/workspace/Insam/train\\하_20220819_Xray_00116...     하\n",
       "17051      134016  C:/workspace/Insam/train\\하_20220830_Xray_00187...     하\n",
       "\n",
       "[17052 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e59f0",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cde3726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "The predicted label for './test/상_20220706_Xray_002467.jpg' is 상\n"
     ]
    }
   ],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, class_n, rate=0.2):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        self.output_layer = nn.Linear(in_features=1000, out_features=class_n, bias=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.output_layer(self.dropout(self.model(inputs)))\n",
    "        return output\n",
    "\n",
    "mytransform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model = CNN_Model(4).to('cuda')\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "image_path = './test/상_20220706_Xray_002467.jpg'\n",
    "image = Image.open(image_path)\n",
    "image = mytransform(image).unsqueeze(0).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    label_mapping = {0: '상', 1: '중', 2: '하', 3: '최하'}\n",
    "    predicted_label = label_mapping[predicted.item()]\n",
    "\n",
    "print(f\"The predicted label for '{image_path}' is {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a2091df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 17539/17539 [00:07<00:00, 2312.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv 파일이 성공적으로 생성되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_dir = 'C://workspace//Insam//test/' \n",
    "test_files = os.listdir(test_dir)\n",
    "\n",
    "test_df = pd.DataFrame(columns=['file_path', 'label'])\n",
    "\n",
    "for file_name in tqdm(test_files):\n",
    "    file_path = os.path.join(test_dir, file_name)\n",
    "    label = file_name.split('_')[0]\n",
    "    test_df = test_df.append({'file_path': file_path, 'label': label}, ignore_index=True)\n",
    "    \n",
    "test_df.to_csv('test_df.csv', index=False)\n",
    "\n",
    "print(\"test.csv 파일이 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e297a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C://workspace//Insam//test/상_20220706_Xray_002...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C://workspace//Insam//test/상_20220706_Xray_002...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C://workspace//Insam//test/상_20220706_Xray_002...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C://workspace//Insam//test/상_20220708_Xray_000...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C://workspace//Insam//test/상_20220708_Xray_001...</td>\n",
       "      <td>상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17534</th>\n",
       "      <td>C://workspace//Insam//test/하_20220930_Xray_003...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17535</th>\n",
       "      <td>C://workspace//Insam//test/하_20220930_Xray_003...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17536</th>\n",
       "      <td>C://workspace//Insam//test/하_20220930_Xray_003...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17537</th>\n",
       "      <td>C://workspace//Insam//test/하_20220930_Xray_003...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17538</th>\n",
       "      <td>C://workspace//Insam//test/하_20220930_Xray_003...</td>\n",
       "      <td>하</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17539 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_path label\n",
       "0      C://workspace//Insam//test/상_20220706_Xray_002...     상\n",
       "1      C://workspace//Insam//test/상_20220706_Xray_002...     상\n",
       "2      C://workspace//Insam//test/상_20220706_Xray_002...     상\n",
       "3      C://workspace//Insam//test/상_20220708_Xray_000...     상\n",
       "4      C://workspace//Insam//test/상_20220708_Xray_001...     상\n",
       "...                                                  ...   ...\n",
       "17534  C://workspace//Insam//test/하_20220930_Xray_003...     하\n",
       "17535  C://workspace//Insam//test/하_20220930_Xray_003...     하\n",
       "17536  C://workspace//Insam//test/하_20220930_Xray_003...     하\n",
       "17537  C://workspace//Insam//test/하_20220930_Xray_003...     하\n",
       "17538  C://workspace//Insam//test/하_20220930_Xray_003...     하\n",
       "\n",
       "[17539 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "560432fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▉                                                  | 2142/17539 [01:09<08:06, 31.65it/s]"
     ]
    }
   ],
   "source": [
    "model = CNN_Model(4).to('cuda')\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "correct_predictions = 0\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    image_path = row['file_path']\n",
    "    true_label = row['label']\n",
    "\n",
    "    # 이미지 불러오기 및 전처리\n",
    "    image = Image.open(image_path)\n",
    "    image = mytransform(image).unsqueeze(0).to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        label_mapping = {0: '상', 1: '중', 2: '하', 3: '최하'}\n",
    "        predicted_label = label_mapping[predicted.item()]\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(test_df)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f841ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:31<00:00, 31.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, class_n, rate=0.2):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        self.output_layer = nn.Linear(in_features=1000, out_features=class_n, bias=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.output_layer(self.dropout(self.model(inputs)))\n",
    "        return output\n",
    "\n",
    "model = CNN_Model(4).to('cuda')\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "test_sample_df = test_df.sample(n=1000, random_state=42)\n",
    "correct_predictions = 0\n",
    "\n",
    "for index, row in tqdm(test_sample_df.iterrows(), total=len(test_sample_df)):\n",
    "    image_path = row['file_path']\n",
    "    true_label = row['label']\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    image = mytransform(image).unsqueeze(0).to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        label_mapping = {0: '상', 1: '중', 2: '하', 3: '최하'}\n",
    "        predicted_label = label_mapping[predicted.item()]\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(test_sample_df)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e10909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
